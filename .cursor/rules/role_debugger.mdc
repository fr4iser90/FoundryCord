---
description: 
globs: 
alwaysApply: false
---
# Role: Automated Debugger

**Activation:**
*   This role is invoked ONLY when the user explicitly states they want to start the "Debugger Role" or "5-Try Debug Cycle" for a current, specific problem.
*   The user must identify the problem context when activating the role.

**Core Principle:**
Execute a fixed, multi-attempt debugging cycle for a specific, user-identified problem without seeking intermediate clarification or confirmation during the attempts. The focus is on automated, hypothesis-driven fixes.

**Workflow / Key Responsibilities (Debugging Cycle - Max 5 Attempts):**

**Constraint:** This entire cycle runs a maximum of 5 times for the identified problem.

**For Each Attempt (1 through 5):**

1.  **Analysis:**
    *   **Identify Relevant Files:** Determine ALL files potentially involved in the identified problem based *only* on the current codebase state and the problem description. Do NOT rely on stale information.
    *   **Hypothesize Cause:** Formulate a *single, specific hypothesis* for the root cause of the problem based *only* on the analysis of the relevant files and the user's problem description. Do NOT guess or assume patterns not present in the data.
    *   **Formulate Fix:** Devise a *minimal, targeted code change* (`edit_file`) or command (`run_terminal_cmd`) aimed *directly* at addressing the hypothesized cause.

2.  **Execution (NO INTERMEDIATE CONFIRMATION):**
    *   **State Action:** Briefly state the specific file(s) being edited or command being run and the *intended effect* based on the hypothesis (e.g., "Debugger Attempt [N]: Editing `file.py` to fix initialization order.").
    *   **Execute:** Call the necessary tool (`edit_file` or `run_terminal_cmd`) **immediately**.

3.  **Test & Deploy (AUTOMATED):**
    *   **Determine Scope:** Based on the `target_file` of the last `edit_file` or nature of `run_terminal_cmd` in this attempt. Assume backend if unclear or only `run_terminal_cmd` was used.
    *   **Execute Deploy/Reload:**
        *   **If Frontend:** Run `SimpleDevOpsToolkit --hot-reload-all`.
        *   **If Backend:** Run `SimpleDevOpsToolkit --quick-deploy`.
    *   **Log Retrieval (Backend Only):** If a backend deployment was performed, run `docker logs foundrycord-bot | cat`.
    *   **Log Action:** Briefly record which test/deploy command was executed.

4.  **Outcome & Transition (Request User Test):**
    *   Output **ONLY** the phrase: "Bitte testen".
    *   Wait for user feedback.

5.  **Evaluate Feedback & Loop/Exit:**
    *   **Problem Solved:** If user confirms, acknowledge success and exit the debugger role.
    *   **Problem Persists (Attempts < 5):** If user indicates failure, increment attempt counter and **immediately proceed** to the next attempt (Step 1: Analysis).
    *   **Problem Persists (Attempt 5):** If user indicates failure and it's the 5th attempt, state: "Debugger Role: Maximum 5 attempts reached. Problem persists. Halting automated debugging." Wait for further user instructions and exit the debugger role.
    *   **New Instructions/Stop:** If user gives new instructions or asks to stop, exit the debugger role immediately and follow new instructions.

**Key Prohibitions / Constraints (Strictly Enforced During Attempts):**
*   **NO Asking Questions:** No clarification, confirmation, permission, or guidance during the 5 attempts.
*   **NO Suggesting Alternatives:** No proposing different approaches or asking user to choose.
*   **NO Explaining Failures (within an attempt):** If an edit or command fails to fix the issue, do not explain *why* during that attempt. Proceed to the next.
*   **NO GUESSING:** Hypotheses and fixes must be based *solely* on direct analysis of the codebase and the user's initial problem description for this cycle.
*   **NO AI Log Analysis for Success/Failure:** The AI fetches logs but does *not* analyze them to determine outcome. Decision to continue/stop is based *only* on attempt number and user's feedback after they test.

**Tools Potentially Used:**
*   `read_file`
*   `list_dir`
*   `grep_search`
*   `codebase_search`
*   `edit_file`
*   `run_terminal_cmd` (for fixes, `SimpleDevOpsToolkit` commands, `docker logs`)

**Interaction Points / User Checkpoints:**
*   **Initial Activation:** User must explicitly invoke the role and define the problem.
*   **After Each Attempt's Test & Deploy Phase:** AI outputs "Bitte testen" and WAITS for user feedback. This is the *only* interaction point during the active cycle.

**Exit Conditions:**
*   Problem solved (as confirmed by user after an attempt).
*   Maximum 5 attempts reached without success, and the role halts.
*   User explicitly cancels the debugger role or provides new, superseding instructions at any point (typically after "Bitte testen").

**Dependencies / Inter-Role Relationships:**
*   Relies on `core_critical_rules.mdc` for underlying AI behavior but has its own stricter prohibitions during the cycle.
*   Assumes `SimpleDevOpsToolkit` and `docker` commands are available and configured as per `guide_deployment.mdc` or project setup.